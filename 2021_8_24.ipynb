{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_8_24.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6XclOmtIoKeyqxRgTZmrv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xxp-nlp/add_tag_algorithm/blob/main/2021_8_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h14koQHuHY1z",
        "outputId": "22570e45-71a3-4f90-e45f-147c5aa47734"
      },
      "source": [
        "import re\n",
        "\n",
        "filename = '/content/CiWoTestdata-Correct.txt'\n",
        "\n",
        "dependancy = re.compile(r'''(?:\\*\\s\\d+\\s) # キャプチャ対象外\n",
        "             (-?\\d+)      # 数字(係り先)\n",
        "                      ''', re.VERBOSE)\n",
        "\n",
        "class Morph:\n",
        "    def __init__(self, line):\n",
        "        cols = line.split(' ')\n",
        "        self.surface = cols[0] # 表層形(surface)\n",
        "\n",
        "class Chunk_correct:\n",
        "    def __init__(self, morphs, dst, id):\n",
        "        self.morphs = morphs\n",
        "        self.dst  = dst  # 係り先文節インデックス番号\n",
        "        self.id = id\n",
        "        self.phrase = ''.join([morph.surface for morph in morphs]) # 文節\n",
        "        self.trim_phrase = self.phrase.replace('、','')\n",
        "        self.tag = 'KEEP'\n",
        "\n",
        "sentences = []\n",
        "chunks = []\n",
        "morphs = []\n",
        "ids = []\n",
        "dic_correct = {}\n",
        "i = 0\n",
        "with open(filename, mode='r') as f:\n",
        "  for line in f:  # 1行ずつ読込\n",
        "    dependancies = dependancy.match(line)\n",
        "    fields = line.split(' ')\n",
        "\n",
        "\n",
        "    if fields[0] == '#':\n",
        "      id = fields[1]\n",
        "      continue\n",
        "\n",
        "    # EOSまたは係り受け解析結果でない場合\n",
        "    if not (line == 'EOS\\n' or dependancies):\n",
        "      morphs.append(Morph(line))\n",
        "\n",
        "\n",
        "    # EOSまたは係り受け解析結果で、形態素解析結果がある場合\n",
        "    elif len(morphs) > 0:\n",
        "      chunks.append(Chunk_correct(morphs, dst, id))\n",
        "      morphs = []  \n",
        "\n",
        "    # 係り受け結果の場合\n",
        "    if dependancies:\n",
        "      dst = int(dependancies.group(1))\n",
        "\n",
        "    # EOSで係り受け結果がある場合\n",
        "    if line == 'EOS\\n' and len(chunks) > 0:\n",
        "      sentences.append(chunks)\n",
        "      chunks = []\n",
        "      dic_correct[i] = [sentences,id]\n",
        "      i+=1\n",
        "\n",
        "for i, chunk in enumerate(sentences[9]):\n",
        "    print('{}: {}  係り先:{} {}'.format(i, chunk.trim_phrase, chunk.dst, chunk.tag))"
      ],
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 同大統領の  係り先:1 KEEP\n",
            "1: 首都脱出は  係り先:9 KEEP\n",
            "2: 先に  係り先:9 KEEP\n",
            "3: インタファクス通信が  係り先:9 KEEP\n",
            "4: 六日  係り先:9 KEEP\n",
            "5: グロズヌイの  係り先:6 KEEP\n",
            "6: 軍事筋の  係り先:7 KEEP\n",
            "7: 情報と  係り先:8 KEEP\n",
            "8: して  係り先:9 KEEP\n",
            "9: 伝えたが  係り先:13 KEEP\n",
            "10: ロシア政府が  係り先:12 KEEP\n",
            "11: 公式に  係り先:12 KEEP\n",
            "12: 認めたのは  係り先:13 KEEP\n",
            "13: 初めて。  係り先:-1 KEEP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7ZNQYoPHngQ",
        "outputId": "abb2248a-7b94-41b0-8972-396031dbbd92"
      },
      "source": [
        "filename = '/content/CiWoTestdata.txt'\n",
        "\n",
        "dependancy = re.compile(r'''(?:\\*\\s\\d+\\s) # キャプチャ対象外\n",
        "             (-?\\d+)      # 数字(係り先)\n",
        "                      ''', re.VERBOSE)\n",
        "\n",
        "class Morph:\n",
        "    def __init__(self, line):\n",
        "        cols = line.split(' ')\n",
        "        self.surface = cols[0] # 表層形(surface)\n",
        "\n",
        "\n",
        "class Chunk_wrong:\n",
        "    def __init__(self, morphs, dst, id):\n",
        "        self.morphs = morphs\n",
        "        self.dst  = dst  # 係り先文節インデックス番号\n",
        "        self.id = id\n",
        "        self.phrase = ''.join([morph.surface for morph in morphs]) # 文節\n",
        "        self.trim_phrase = self.phrase.replace('、','')\n",
        "        self.tag = 'KEEP'\n",
        "\n",
        "dic_wrong = {}\n",
        "sentences_wrong = []\n",
        "chunks = []\n",
        "morphs = []\n",
        "ids = []\n",
        "i = 0\n",
        "with open(filename, mode='r') as f:\n",
        "  for line in f:  # 1行ずつ読込\n",
        "    dependancies = dependancy.match(line)\n",
        "    fields = line.split(' ')\n",
        "\n",
        "\n",
        "    if fields[0] == '#':\n",
        "      id = fields[1]\n",
        "      continue\n",
        "\n",
        "    # EOSまたは係り受け解析結果でない場合\n",
        "    if not (line == 'EOS\\n' or dependancies):\n",
        "      morphs.append(Morph(line))\n",
        "\n",
        "\n",
        "    # EOSまたは係り受け解析結果で、形態素解析結果がある場合\n",
        "    elif len(morphs) > 0:\n",
        "      chunks.append(Chunk_wrong(morphs, dst, id))\n",
        "      morphs = []  \n",
        "\n",
        "    # 係り受け結果の場合\n",
        "    if dependancies:\n",
        "      dst = int(dependancies.group(1))\n",
        "\n",
        "    # EOSで係り受け結果がある場合\n",
        "    if line == 'EOS\\n' and len(chunks) > 0:\n",
        "      sentences_wrong.append(chunks)\n",
        "      chunks = []\n",
        "      dic_wrong[i] = [sentences_wrong,id]\n",
        "      i+=1\n",
        "\n",
        "\n",
        "for i, chunk in enumerate(sentences_wrong[1]):\n",
        "    print('{}: {}  係り先:{} {}'.format(i, chunk.trim_phrase, chunk.dst, chunk.tag))"
      ],
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 党全体での  係り先:1 KEEP\n",
            "1: 新党移行を  係り先:4 KEEP\n",
            "2: 今春の  係り先:3 KEEP\n",
            "3: 統一地方選後に  係り先:4 KEEP\n",
            "4: 目指す  係り先:5 KEEP\n",
            "5: 考えを  係り先:6 KEEP\n",
            "6: 強調  係り先:12 KEEP\n",
            "7: 離党など  係り先:9 KEEP\n",
            "8: 性急な  係り先:9 KEEP\n",
            "9: 行動への  係り先:10 KEEP\n",
            "10: 自重を  係り先:12 KEEP\n",
            "11: 首相は  係り先:12 KEEP\n",
            "12: 求めた。  係り先:-1 KEEP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH6Szh3CHpvw",
        "outputId": "50f14304-59db-4830-b80c-7b2504760d57"
      },
      "source": [
        "# scale the data\n",
        "lenth = min(len(sentences),len(sentences_wrong))\n",
        "\n",
        "print(\"読みやすい文：\",len(sentences))\n",
        "print(\"読みにくい文：\",len(sentences_wrong))\n",
        "\n",
        "correct = []\n",
        "wrong = []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  for j in range(len(sentences_wrong)):\n",
        "    if dic_correct[i][1] == dic_wrong[j][1]:  \n",
        "      correct.append(sentences[i])\n",
        "      wrong.append(sentences_wrong[j])\n",
        "      \n"
      ],
      "execution_count": 500,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "読みやすい文： 530\n",
            "読みにくい文： 546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "couVUEsvU7b3"
      },
      "source": [
        "def algo(wrong,correct):\n",
        "  dic2 = {}\n",
        "\n",
        "  for i in range(2):\n",
        "\n",
        "    for j in range(len(wrong[i])):\n",
        "      if wrong[i][j].trim_phrase not in dic2:\n",
        "        dic2[wrong[i][j].trim_phrase] = [] \n",
        "      dic2[wrong[i][j].trim_phrase].append(j)\n",
        "\n",
        "\n",
        "    for j in range(len(correct[i])):\n",
        "      if j == len(correct[i])-1:\n",
        "        break\n",
        "\n",
        "      for m in range(len(dic2[correct[i][j].trim_phrase])):\n",
        "        for n in range(len(dic2[correct[i][j+1].trim_phrase])):\n",
        "          if correct[i][j].dst == j+1 and dic2[correct[i][j].trim_phrase][m] == dic2[correct[i][j+1].trim_phrase][n] - 1:\n",
        "            wrong[i][dic2[correct[i][j].trim_phrase][m]].tag = \"REDUCE\"\n",
        "            correct[i][j].tag = \"REDUCE\"\n",
        "\n",
        "          if dic2[correct[i][j].trim_phrase][m] < len(wrong[i])-1 and dic2[correct[i][j].trim_phrase][m] == dic2[correct[i][j+1].trim_phrase][n] + 1: \n",
        "            wrong[i][dic2[sentences[i][j].trim_phrase][m]].tag = \"SWAP_B\"\n",
        "            wrong[i][dic2[sentences[i][j+1].trim_phrase][n]].tag = \"SWAP_F\"\n",
        "\n",
        "    dic2 = {}"
      ],
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cohiZhOU7S6"
      },
      "source": [
        "algo(wrong,correct)"
      ],
      "execution_count": 502,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66gOsVMBHuWI",
        "outputId": "ccd131e6-99e1-49f6-865f-a8b259a41820"
      },
      "source": [
        "# step1の結果確認\n",
        "for i in range(9,10):\n",
        "  print(\"-------  sentence \", i+1, \"-------\")\n",
        "  for j, chunk in enumerate(wrong[i]):\n",
        "    print('{}: {}: {}'.format(j, wrong[i][j].trim_phrase, wrong[i][j].tag))"
      ],
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------  sentence  10 -------\n",
            "0: 公式に: KEEP\n",
            "1: ロシア政府が: KEEP\n",
            "2: 認めたのは: KEEP\n",
            "3: 同大統領の: KEEP\n",
            "4: 首都脱出は: KEEP\n",
            "5: 先に: KEEP\n",
            "6: 六日: KEEP\n",
            "7: グロズヌイの: KEEP\n",
            "8: 軍事筋の: KEEP\n",
            "9: 情報と: KEEP\n",
            "10: して: KEEP\n",
            "11: インタファクス通信が: KEEP\n",
            "12: 伝えたが: KEEP\n",
            "13: 初めて。: KEEP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_f1Sqv-HvyI",
        "outputId": "ce8cd2ef-6d0b-4c3c-e9e7-ba2673e8cdd2"
      },
      "source": [
        "# step1の結果確認\n",
        "for i in range(9,10):\n",
        "  print(\"-------  sentence \", i+1, \"-------\")\n",
        "  for j, chunk in enumerate(correct[i]):\n",
        "    print('{}: {}: {}'.format(j, chunk.trim_phrase, chunk.tag))"
      ],
      "execution_count": 504,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------  sentence  10 -------\n",
            "0: 同大統領の: KEEP\n",
            "1: 首都脱出は: KEEP\n",
            "2: 先に: KEEP\n",
            "3: インタファクス通信が: KEEP\n",
            "4: 六日: KEEP\n",
            "5: グロズヌイの: KEEP\n",
            "6: 軍事筋の: KEEP\n",
            "7: 情報と: KEEP\n",
            "8: して: KEEP\n",
            "9: 伝えたが: KEEP\n",
            "10: ロシア政府が: KEEP\n",
            "11: 公式に: KEEP\n",
            "12: 認めたのは: KEEP\n",
            "13: 初めて。: KEEP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPZVH9YdYG1N"
      },
      "source": [
        "class Chunk_temp:\n",
        "    def __init__(self, trim_phrase, tag ,dst):\n",
        "      self.trim_phrase = trim_phrase\n",
        "      self.tag = tag\n",
        "      self.dst = dst\n",
        "\n",
        "class New_chunk:\n",
        "    def __init__(self, new_chunk):\n",
        "      self.trim_phrase = new_chunk[0]\n",
        "      self.tag = new_chunk[1]\n",
        "      self.dst = new_chunk[2]\n",
        "\n",
        "    def change(self):\n",
        "      chunks = []\n",
        "      \n",
        "      for i in range(len(self.dst)):\n",
        "#        print(self.trim_phrase[i], self.tag[i], self.dst[i])\n",
        "        chunks.append(Chunk_temp(self.trim_phrase[i], self.tag[i], self.dst[i]))\n",
        "#        print(\"------------\")\n",
        "      return chunks\n",
        "\n",
        "\n",
        "\n",
        "class Merged:\n",
        "  def __init__(self, j, phrase, trim_phrase, tag, dst):\n",
        "    self.j = j\n",
        "    self.phrase = phrase\n",
        "    self.trim_phrases = trim_phrase\n",
        "    self.tag = tag\n",
        "    self.dst = dst\n",
        "\n",
        "  def merge(self):\n",
        "    new_phrase = []\n",
        "    new_tag = []\n",
        "    index = []\n",
        "    set1 = set([])\n",
        "    str1 = ''\n",
        "    list_dst = []\n",
        "\n",
        "    for i in range(j+1):\n",
        "      if tag[i] == 'REDUCE':\n",
        "        set1.add(i)\n",
        "        set1.add(i+1)\n",
        "\n",
        "      if tag[i] == 'KEEP':\n",
        "        temp_list = list(set1)\n",
        "        temp_list.sort()\n",
        "        if len(temp_list)>0:\n",
        "#          print(dst[temp_list[-1]])\n",
        "          list_dst.append(dst[temp_list[-1]])\n",
        "        for i in temp_list:\n",
        "          str1 += trim_phrase[i]\n",
        "#          print(i,str1)\n",
        "        if len(str1)>0:\n",
        "          new_phrase.append(str1)\n",
        "          index.append(list(set1))\n",
        "          new_tag.append(\"KEEP\")\n",
        "          str1 = ''\n",
        "          set1.clear()\n",
        "        else: \n",
        "          new_phrase.append(trim_phrase[i])\n",
        "          new_tag.append(\"KEEP\")\n",
        "          index.append(i)\n",
        "#          print(dst[i])\n",
        "          list_dst.append(dst[i])\n",
        "          \n",
        "\n",
        "      if tag[i] == 'SWAP_F':\n",
        "        new_phrase.append(trim_phrase[i+1])\n",
        "        new_tag.append(\"KEEP\")\n",
        "        index.append(i+1)\n",
        "      if tag[i] == 'SWAP_B':\n",
        "        new_phrase.append(trim_phrase[i-1])\n",
        "        new_tag.append(\"KEEP\")\n",
        "        index.append(i-1)\n",
        "\n",
        "    new_dst = []\n",
        "    for m in range(len(list_dst)):\n",
        "      for n in range(len(index)):\n",
        "        if isinstance(index[n],int):\n",
        "          if list_dst[m] == index[n]:\n",
        "#            print(n)\n",
        "            new_dst.append(n)\n",
        "\n",
        "        else:\n",
        "          for k in range(len(index[n])):\n",
        "            if list_dst[m] == index[n][k]:\n",
        "#              print(n)\n",
        "              new_dst.append(n)\n",
        "\n",
        "    new_dst.append(-1)\n",
        "\n",
        "    return new_phrase,new_tag,new_dst\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "# main\n",
        "\n",
        "phrase = []\n",
        "trim_phrase = []\n",
        "tag = []\n",
        "dst = []\n",
        "\n",
        "new_chunks = []\n",
        "\n",
        "correct_new_chunks = []\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "   \n",
        "  for j, chunk in enumerate(wrong[i]):\n",
        "    phrase.append(chunk.phrase)\n",
        "    trim_phrase.append(chunk.trim_phrase)\n",
        "    tag.append(chunk.tag)\n",
        "    dst.append(chunk.dst)\n",
        "\n",
        "  new_chunk = Merged(j, phrase, trim_phrase, tag, dst).merge()\n",
        "  phrase = []\n",
        "  trim_phrase = []\n",
        "  tag = []\n",
        "  dst = []\n",
        "  temp_chunk = New_chunk(new_chunk).change()\n",
        "  new_chunks.append(temp_chunk)\n",
        "\n",
        "  for j, chunk in enumerate(correct[i]):\n",
        "    phrase.append(chunk.phrase)\n",
        "    trim_phrase.append(chunk.trim_phrase)\n",
        "    tag.append(chunk.tag)\n",
        "    dst.append(chunk.dst)\n",
        "  \n",
        "  # print(trim_phrase)  \n",
        "  # print(tag)\n",
        "  # print(dst)    \n",
        "\n",
        "  correct_new_chunk = Merged(j, phrase, trim_phrase, tag, dst).merge()\n",
        "  phrase = []\n",
        "  trim_phrase = []\n",
        "  tag = []\n",
        "  dst = []\n",
        "  temp_correct_chunk = New_chunk(correct_new_chunk).change()\n",
        "  correct_new_chunks.append(temp_correct_chunk)\n"
      ],
      "execution_count": 505,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRfVnQCSHyhw",
        "outputId": "5c23f214-904a-4bd3-e169-af9b7f692ca0"
      },
      "source": [
        "for i in range(2):\n",
        "  print('------------sentence:',i+1,'----------------')\n",
        "  for j in range(len(new_chunks[i])):\n",
        "    print(j, new_chunks[i][j].trim_phrase, new_chunks[i][j].tag, new_chunks[i][j].dst)"
      ],
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------sentence: 1 ----------------\n",
            "0 同社では KEEP 4\n",
            "1 準役員クラス以上に KEEP 4\n",
            "2 能力重視型の年俸制を KEEP 4\n",
            "3 すでに KEEP 4\n",
            "4 導入している。 KEEP -1\n",
            "------------sentence: 2 ----------------\n",
            "0 党全体での新党移行を KEEP 2\n",
            "1 今春の統一地方選後に KEEP 2\n",
            "2 目指す考えを強調 KEEP 6\n",
            "3 離党など KEEP 4\n",
            "4 性急な行動への自重を KEEP 6\n",
            "5 首相は KEEP 6\n",
            "6 求めた。 KEEP -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Iu8UsKSvyJx"
      },
      "source": [
        "# new_chunks[0][2].trim_phrase = 'すでに'\n",
        "# new_chunks[0][3].trim_phrase = '能力重視型の年俸制を'"
      ],
      "execution_count": 507,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve4Eqfy4wS7g"
      },
      "source": [
        "# for i in range(1):\n",
        "#   print('------------sentence:',i+1,'----------------')\n",
        "#   for j in range(len(new_chunks[i])):\n",
        "#     print(j, new_chunks[i][j].trim_phrase, new_chunks[i][j].tag, new_chunks[i][j].dst)"
      ],
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIdeDy2pH0Ro",
        "outputId": "d4f26815-4963-47e4-eb5b-8fd65bf35966"
      },
      "source": [
        "for i in range(2):\n",
        "  print('------------sentence:',i+1,'----------------')\n",
        "  for j in range(len(correct_new_chunks[i])):\n",
        "    print(j, correct_new_chunks[i][j].trim_phrase, correct_new_chunks[i][j].tag, correct_new_chunks[i][j].dst)"
      ],
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------sentence: 1 ----------------\n",
            "0 同社では KEEP 4\n",
            "1 すでに KEEP 4\n",
            "2 準役員クラス以上に KEEP 4\n",
            "3 能力重視型の年俸制を KEEP 4\n",
            "4 導入している。 KEEP -1\n",
            "------------sentence: 2 ----------------\n",
            "0 首相は KEEP 6\n",
            "1 今春の統一地方選後に KEEP 3\n",
            "2 党全体での新党移行を KEEP 3\n",
            "3 目指す考えを強調 KEEP 6\n",
            "4 離党など KEEP 5\n",
            "5 性急な行動への自重を KEEP 6\n",
            "6 求めた。 KEEP -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Ue1v3qLVWBjW",
        "outputId": "8e816c1b-a60d-404e-9f76-f9dc229a5d43"
      },
      "source": [
        "algo(new_chunks,correct_new_chunks)"
      ],
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-510-605d2e5652e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_chunks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrect_new_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-501-91bd3a3b4ed1>\u001b[0m in \u001b[0;36malgo\u001b[0;34m(wrong, correct)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdic2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrim_phrase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdic2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrim_phrase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdic2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrim_phrase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mwrong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdic2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrim_phrase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SWAP_B\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mwrong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdic2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrim_phrase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SWAP_F\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '今春の'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To39Ppl0ocpn"
      },
      "source": [
        "for i in range(2):\n",
        "  print('------------sentence:',i+1,'----------------')\n",
        "  for j in range(len(new_chunks[i])):\n",
        "    print(j, new_chunks[i][j].trim_phrase, new_chunks[i][j].tag, new_chunks[i][j].dst)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}