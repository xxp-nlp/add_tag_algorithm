{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_8_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXfQwa6ciuH7ju2GyYSVWR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xxp-nlp/add_tag_algorithm/blob/main/2021_8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7L7GrtJJ93O",
        "outputId": "a409d20c-602c-4299-c95c-916decc7b00c"
      },
      "source": [
        "import re\n",
        "\n",
        "filename = '/content/CiWoTestdata-Correct.txt'\n",
        "\n",
        "dependancy = re.compile(r'''(?:\\*\\s\\d+\\s) # キャプチャ対象外\n",
        "             (-?\\d+)      # 数字(係り先)\n",
        "                      ''', re.VERBOSE)\n",
        "\n",
        "class Morph:\n",
        "    def __init__(self, line):\n",
        "        cols = line.split(' ')\n",
        "        self.surface = cols[0] # 表層形(surface)\n",
        "\n",
        "\n",
        "class Chunk_correct:\n",
        "    def __init__(self, morphs, dst, id):\n",
        "        self.morphs = morphs\n",
        "        self.dst  = dst  # 係り先文節インデックス番号\n",
        "        self.id = id\n",
        "        self.phrase = ''.join([morph.surface for morph in morphs]) # 文節\n",
        "        self.trim_phrase = self.phrase.replace('、','')\n",
        "\n",
        "sentences = []\n",
        "chunks = []\n",
        "morphs = []\n",
        "ids = []\n",
        "dic_correct = {}\n",
        "i = 0\n",
        "with open(filename, mode='r') as f:\n",
        "  for line in f:  # 1行ずつ読込\n",
        "    dependancies = dependancy.match(line)\n",
        "    fields = line.split(' ')\n",
        "\n",
        "\n",
        "    if fields[0] == '#':\n",
        "      id = fields[1]\n",
        "      continue\n",
        "\n",
        "    # EOSまたは係り受け解析結果でない場合\n",
        "    if not (line == 'EOS\\n' or dependancies):\n",
        "      morphs.append(Morph(line))\n",
        "\n",
        "\n",
        "    # EOSまたは係り受け解析結果で、形態素解析結果がある場合\n",
        "    elif len(morphs) > 0:\n",
        "      chunks.append(Chunk_correct(morphs, dst, id))\n",
        "      morphs = []  \n",
        "\n",
        "    # 係り受け結果の場合\n",
        "    if dependancies:\n",
        "      dst = int(dependancies.group(1))\n",
        "\n",
        "    # EOSで係り受け結果がある場合\n",
        "    if line == 'EOS\\n' and len(chunks) > 0:\n",
        "      sentences.append(chunks)\n",
        "      chunks = []\n",
        "      dic_correct[i] = [sentences,id]\n",
        "      i+=1\n",
        "\n",
        "for i, chunk in enumerate(sentences[1]):\n",
        "    print('{}: {}  係り先:{}'.format(i, chunk.trim_phrase, chunk.dst))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 首相は  係り先:12\n",
            "1: 今春の  係り先:2\n",
            "2: 統一地方選後に  係り先:5\n",
            "3: 党全体での  係り先:4\n",
            "4: 新党移行を  係り先:5\n",
            "5: 目指す  係り先:6\n",
            "6: 考えを  係り先:7\n",
            "7: 強調  係り先:12\n",
            "8: 離党など  係り先:10\n",
            "9: 性急な  係り先:10\n",
            "10: 行動への  係り先:11\n",
            "11: 自重を  係り先:12\n",
            "12: 求めた。  係り先:-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsQpnrJ-U-TE",
        "outputId": "2caed43a-ad26-4660-dd07-09749f2580b5"
      },
      "source": [
        "filename = '/content/CiWoTestdata.txt'\n",
        "\n",
        "dependancy = re.compile(r'''(?:\\*\\s\\d+\\s) # キャプチャ対象外\n",
        "             (-?\\d+)      # 数字(係り先)\n",
        "                      ''', re.VERBOSE)\n",
        "\n",
        "class Morph:\n",
        "    def __init__(self, line):\n",
        "        cols = line.split(' ')\n",
        "        self.surface = cols[0] # 表層形(surface)\n",
        "\n",
        "\n",
        "class Chunk_wrong:\n",
        "    def __init__(self, morphs, dst, id):\n",
        "        self.morphs = morphs\n",
        "        self.dst  = dst  # 係り先文節インデックス番号\n",
        "        self.id = id\n",
        "        self.phrase = ''.join([morph.surface for morph in morphs]) # 文節\n",
        "        self.trim_phrase = self.phrase.replace('、','')\n",
        "        self.tag = 'KEEP'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dic_wrong = {}\n",
        "sentences_wrong = []\n",
        "chunks = []\n",
        "morphs = []\n",
        "ids = []\n",
        "i = 0\n",
        "with open(filename, mode='r') as f:\n",
        "  for line in f:  # 1行ずつ読込\n",
        "    dependancies = dependancy.match(line)\n",
        "    fields = line.split(' ')\n",
        "\n",
        "\n",
        "    if fields[0] == '#':\n",
        "      id = fields[1]\n",
        "      continue\n",
        "\n",
        "    # EOSまたは係り受け解析結果でない場合\n",
        "    if not (line == 'EOS\\n' or dependancies):\n",
        "      morphs.append(Morph(line))\n",
        "\n",
        "\n",
        "    # EOSまたは係り受け解析結果で、形態素解析結果がある場合\n",
        "    elif len(morphs) > 0:\n",
        "      chunks.append(Chunk_wrong(morphs, dst, id))\n",
        "      morphs = []  \n",
        "\n",
        "    # 係り受け結果の場合\n",
        "    if dependancies:\n",
        "      dst = int(dependancies.group(1))\n",
        "\n",
        "    # EOSで係り受け結果がある場合\n",
        "    if line == 'EOS\\n' and len(chunks) > 0:\n",
        "      sentences_wrong.append(chunks)\n",
        "      chunks = []\n",
        "      dic_wrong[i] = [sentences_wrong,id]\n",
        "      i+=1\n",
        "\n",
        "\n",
        "for i, chunk in enumerate(sentences_wrong[1]):\n",
        "    print('{}: {}   {}'.format(i, chunk.trim_phrase, chunk.tag))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 党全体での   KEEP\n",
            "1: 新党移行を   KEEP\n",
            "2: 今春の   KEEP\n",
            "3: 統一地方選後に   KEEP\n",
            "4: 目指す   KEEP\n",
            "5: 考えを   KEEP\n",
            "6: 強調   KEEP\n",
            "7: 離党など   KEEP\n",
            "8: 性急な   KEEP\n",
            "9: 行動への   KEEP\n",
            "10: 自重を   KEEP\n",
            "11: 首相は   KEEP\n",
            "12: 求めた。   KEEP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsXaGyRP_4B0"
      },
      "source": [
        "# scale the data\n",
        "lenth = min(len(sentences),len(sentences_wrong))\n",
        "correct = []\n",
        "wrong = []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  for j in range(len(sentences_wrong)):\n",
        "    if dic_correct[i][1] == dic_wrong[j][1]:  \n",
        "      correct.append(sentences[i])\n",
        "      wrong.append(sentences_wrong[j])\n",
        "      \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IahFLOCcrJE8"
      },
      "source": [
        "# タグ付きアルゴリズム\n",
        "\n",
        "dic2 = {}\n",
        "\n",
        "for i in range(lenth):\n",
        "#  print(\"sentence\",i+1)\n",
        "\n",
        "  for j, chunk in enumerate(wrong[i]):\n",
        "    if wrong[i][j].trim_phrase not in dic2:\n",
        "      dic2[wrong[i][j].trim_phrase] = [] \n",
        "    dic2[wrong[i][j].trim_phrase].append(j)\n",
        "  \n",
        "\n",
        "  for j, chunk in enumerate(correct[i]):\n",
        "    if j == len(correct[i])-1:\n",
        "      break\n",
        "\n",
        "    for m in range(len(dic2[correct[i][j].trim_phrase])):\n",
        "      for n in range(len(dic2[correct[i][j+1].trim_phrase])):\n",
        "\n",
        "        if correct[i][j].dst == j+1 and dic2[correct[i][j].trim_phrase][m] == dic2[correct[i][j+1].trim_phrase][n] - 1: \n",
        "          wrong[i][dic2[correct[i][j].trim_phrase][m]].tag = \"REDUCE\"\n",
        "\n",
        "\n",
        "        if dic2[correct[i][j].trim_phrase][m] < len(wrong[i])-1 and dic2[correct[i][j].trim_phrase][m] == dic2[correct[i][j+1].trim_phrase][n] + 1: \n",
        "          wrong[i][dic2[sentences[i][j].trim_phrase][m]].tag = \"SWAP_B\"\n",
        "          wrong[i][dic2[sentences[i][j+1].trim_phrase][n]].tag = \"SWAP_F\"\n",
        "\n",
        "  dic2 = {}\n",
        "\n",
        "#    print(j,sentences[i][j].trim_phrase,sentences[i][j].dst)\n",
        "#  print(\"------------------------\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui15KxnNiVWS",
        "outputId": "49346f32-bc64-4420-f670-904d1372e3ab"
      },
      "source": [
        "# step1結果確認\n",
        "for i in range(1,2):\n",
        "  print(\"-------  sentence \", i+1, \"-------\")\n",
        "  for j, chunk in enumerate(wrong[i]):\n",
        "    print('{}: {}: {}'.format(j, wrong[i][j].trim_phrase, wrong[i][j].tag))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------  sentence  2 -------\n",
            "0: 党全体での: REDUCE\n",
            "1: 新党移行を: KEEP\n",
            "2: 今春の: REDUCE\n",
            "3: 統一地方選後に: KEEP\n",
            "4: 目指す: REDUCE\n",
            "5: 考えを: REDUCE\n",
            "6: 強調: KEEP\n",
            "7: 離党など: KEEP\n",
            "8: 性急な: REDUCE\n",
            "9: 行動への: REDUCE\n",
            "10: 自重を: KEEP\n",
            "11: 首相は: KEEP\n",
            "12: 求めた。: KEEP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3C8E-wQGdyj"
      },
      "source": [
        "# class Merged:\n",
        "#   def __init__(self, trim_phrase, tag, dst):\n",
        "#     self.trim_phrases = trim_phrase\n",
        "#     self.tag = tag\n",
        "#     self.dst = dst\n",
        "\n",
        "\n",
        "#   def merge(self):\n",
        "    \n",
        "\n",
        "\n",
        "# trim_phrase = []\n",
        "# tag = []\n",
        "# dst = []\n",
        "\n",
        "\n",
        "# for i in range(1):\n",
        "#   merged_list = []\n",
        "#   str1 = ''\n",
        "#   for j, chunk in enumerate(wrong[i]):\n",
        "#     str1 += wrong[i][j].trim_phrase\n",
        "#     if (wrong[i][j].tag == 'KEEP'):\n",
        "#       merged_list.append(Merged(str1,'KEEP',))\n",
        "#       str1 = ''\n",
        "      \n",
        "\n",
        "#   #   trim_phrase.append(chunk.trim_phrase)\n",
        "#   #   tag.append(chunk.tag)\n",
        "#   #   dst.append(chunk.dst)\n",
        "#   # Merged(trim_phrase,tag)\n",
        "#   # trim_phrase = []\n",
        "#   # tag = []\n",
        "#   # dst = []\n",
        "\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVv4Fb5hVPl8"
      },
      "source": [
        "# class New_chunk:\n",
        "#     def __init__(self, new_phrase, new_tag, new_dst):\n",
        "#       self.new_phrase = new_phrase\n",
        "#       self.new_tag = new_tag\n",
        "#       self.new_dst = new_dst\n",
        "\n",
        "\n",
        "\n",
        "# class Merged:\n",
        "#   def __init__(self, j, phrase, trim_phrase, tag):\n",
        "#     self.j = j\n",
        "#     self.phrase = phrase\n",
        "#     self.trim_phrases = trim_phrase\n",
        "#     self.tag = tag\n",
        "\n",
        "#   def merge(self):\n",
        "#     new_phrase = []\n",
        "#     new_tag = []\n",
        "#     index = []\n",
        "#     set1 = set([])\n",
        "#     str1 = ''\n",
        "#     list1 = []\n",
        "#     for i in range(j+1):\n",
        "        \n",
        "#       if tag[i] == 'REDUCE':\n",
        "#         set1.add(i)\n",
        "#         set1.add(i+1)\n",
        "#         list1 = []\n",
        "\n",
        "#       if tag[i] == 'KEEP':\n",
        "#         for i in set1:\n",
        "#           str1 += phrase[i]\n",
        "#         if len(str1)>0:\n",
        "#           new_phrase.append(str1)\n",
        "#           index.append(list(set1))\n",
        "#           new_tag.append(\"KEEP\")\n",
        "#           str1 = ''\n",
        "#           set1.clear()\n",
        "#         else: \n",
        "#           new_phrase.append(phrase[i])\n",
        "#           new_tag.append(\"KEEP\")\n",
        "#           index.append(i)\n",
        "\n",
        "#     print(new_phrase,new_tag,index)\n",
        "\n",
        "\n",
        "    \n",
        "# # main\n",
        "\n",
        "# phrase = []\n",
        "# trim_phrase = []\n",
        "# tag = []\n",
        "\n",
        "\n",
        "# for i in range(1,2):\n",
        "#   for j, chunk in enumerate(wrong[i]):\n",
        "#     phrase.append(chunk.phrase)\n",
        "#     trim_phrase.append(chunk.trim_phrase)\n",
        "#     tag.append(chunk.tag)\n",
        "\n",
        "#   Merged(j, phrase, trim_phrase, tag).merge()\n",
        "#   phrase = []\n",
        "#   trim_phrase = []\n",
        "#   tag = []\n",
        "\n",
        "  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqsRUN6BmZeM"
      },
      "source": [
        "class New_chunk:\n",
        "    def __init__(self, new_chunk):\n",
        "      self.new_phrase = new_chunk[0]\n",
        "      self.new_tag = new_chunk[1]\n",
        "      self.index = new_chunk[2]\n",
        "\n",
        "\n",
        "\n",
        "class Merged:\n",
        "  def __init__(self, j, phrase, trim_phrase, tag):\n",
        "    self.j = j\n",
        "    self.phrase = phrase\n",
        "    self.trim_phrases = trim_phrase\n",
        "    self.tag = tag\n",
        "\n",
        "  def merge(self):\n",
        "    new_phrase = []\n",
        "    new_tag = []\n",
        "    index = []\n",
        "    set1 = set([])\n",
        "    str1 = ''\n",
        "    list1 = []\n",
        "    for i in range(j+1):\n",
        "        \n",
        "      if tag[i] == 'REDUCE':\n",
        "        set1.add(i)\n",
        "        set1.add(i+1)\n",
        "        list1 = []\n",
        "\n",
        "      if tag[i] == 'KEEP':\n",
        "        for i in set1:\n",
        "          str1 += phrase[i]\n",
        "        if len(str1)>0:\n",
        "          new_phrase.append(str1)\n",
        "          index.append(list(set1))\n",
        "          new_tag.append(\"KEEP\")\n",
        "          str1 = ''\n",
        "          set1.clear()\n",
        "        else: \n",
        "          new_phrase.append(phrase[i])\n",
        "          new_tag.append(\"KEEP\")\n",
        "          index.append(i)\n",
        "\n",
        "      if tag[i] == 'SWAP_F':\n",
        "        new_phrase.append(phrase[i+1])\n",
        "        new_tag.append(\"KEEP\")\n",
        "        index.append(i+1)\n",
        "      if tag[i] == 'SWAP_B':\n",
        "        new_phrase.append(phrase[i-1])\n",
        "        new_tag.append(\"KEEP\")\n",
        "        index.append(i-1)\n",
        "\n",
        "    return new_phrase,new_tag,index\n",
        "\n",
        "\n",
        "    \n",
        "# main\n",
        "\n",
        "phrase = []\n",
        "trim_phrase = []\n",
        "tag = []\n",
        "new_chunks = []\n",
        "\n",
        "for i in range(10):\n",
        "  # \n",
        "  for j, chunk in enumerate(wrong[i]):\n",
        "    phrase.append(chunk.phrase)\n",
        "    trim_phrase.append(chunk.trim_phrase)\n",
        "    tag.append(chunk.tag)\n",
        "\n",
        "  new_chunk = Merged(j, phrase, trim_phrase, tag).merge()\n",
        "  phrase = []\n",
        "  trim_phrase = []\n",
        "  tag = []\n",
        "\n",
        "  new_chunks.append(New_chunk(new_chunk))\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7zBC0CI1ho3",
        "outputId": "4ab0bdea-7c88-44e4-bb0e-08e164b97eb0"
      },
      "source": [
        "for i in range(1):\n",
        "  print('{}: {}: {}: {}'.format(i, new_chunks[i].new_phrase, new_chunks[i].new_tag, new_chunks[i].index))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: ['同社では、', '準役員クラス以上に', '能力重視型の年俸制を', 'すでに', '導入している。']: ['KEEP', 'KEEP', 'KEEP', 'KEEP', 'KEEP']: [0, 1, [2, 3], 4, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PArl2lVpuW07",
        "outputId": "6228b55b-aca2-430d-98ce-8eeb261ba610"
      },
      "source": [
        "\n",
        "index_list = []\n",
        "for i in range(2):\n",
        "  temp_list = []\n",
        "  for j in range(len(new_chunks[i].index)):\n",
        "    if isinstance(new_chunks[i].index[j],int):\n",
        "      temp_list.append(new_chunks[i].index[j])\n",
        "    else:\n",
        "      temp_list.append(new_chunks[i].index[j][-1])\n",
        "  index_list.append(temp_list)\n",
        "  temp_list = []\n",
        "\n",
        "for i in range(len(index_list)):\n",
        "  print(index_list[i])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 3, 4, 5]\n",
            "[1, 3, 6, 7, 10, 11, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPYNy9uOxHwR",
        "outputId": "c034748e-b3e0-4e48-f09a-08321c526c28"
      },
      "source": [
        "# step1結果確認\n",
        "for i in range(1,2):\n",
        "  \n",
        "  for j in range(len(index_list[1])):\n",
        "    index = index_list[i][j]\n",
        "    print(index, wrong[1][index].trim_phrase)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 新党移行を\n",
            "3 統一地方選後に\n",
            "6 強調\n",
            "7 離党など\n",
            "10 自重を\n",
            "11 首相は\n",
            "12 求めた。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEVND6xY35dk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}